<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Machinelearning : Practical Machine Learning - Coursera">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Machinelearning</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/mdragt/machinelearning">View on GitHub</a>

          <h1 id="project_title">Machinelearning</h1>
          <h2 id="project_tagline">Practical Machine Learning - Coursera</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/mdragt/machinelearning/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/mdragt/machinelearning/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="qualitative-activity-recognition-of-weight-lifting-exercises" class="anchor" href="#qualitative-activity-recognition-of-weight-lifting-exercises" aria-hidden="true"><span class="octicon octicon-link"></span></a>Qualitative Activity Recognition of Weight Lifting Exercises</h1>

<h2>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h2>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. </p>

<p>In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways:</p>

<p>Class A: exactly according to the specification
Class B: throwing the elbows to the front
Class C: lifting the dumbbell only halfway
Class D: lowering the dumbbell only halfway
Class E: throwing the hips to the front</p>

<p>More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset).</p>

<h2>
<a id="goal" class="anchor" href="#goal" aria-hidden="true"><span class="octicon octicon-link"></span></a>Goal</h2>

<p>The goal of this project of the Coursera Practical Machine Learning course is to predict the manner in which people did the exercise. This is the "classe" variable in the training set.</p>

<h2>
<a id="report" class="anchor" href="#report" aria-hidden="true"><span class="octicon octicon-link"></span></a>Report</h2>

<p>This report describes:</p>

<ul>
<li>how this model is built; </li>
<li>how cross validation is used;</li>
<li>what the expected out of sample error is;</li>
<li>justification of the made choices;</li>
<li>Results of prediction model predicting 20 different test cases. </li>
</ul>

<h3>
<a id="reproducibility" class="anchor" href="#reproducibility" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reproducibility</h3>

<p>We set the work dir and start with loading the required libraries. For futher reproducibility, we will set seeds before we create different models.</p>

<pre><code># set work dir
setwd("C:/Users/mdragt/SkyDrive/Coursera/ML")

# load libraries
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(lattice)
library(rattle)
</code></pre>

<h3>
<a id="getting-the-data" class="anchor" href="#getting-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting the data</h3>

<p>We Load the training and test data sets. We wil use the test set for the final validation</p>

<pre><code># read training and testing data for coursera course. 
trainUrl &lt;- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
valUrl &lt;- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
data &lt;- read.csv(url(trainUrl), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))
validation &lt;- read.csv(url(valUrl), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))
</code></pre>

<h3>
<a id="cleaning-and-preparing-the-data" class="anchor" href="#cleaning-and-preparing-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaning and preparing the data</h3>

<p>In this section, we will inspect, clean and prepare the data for further processing.</p>

<p><strong>Inspect the data</strong>
We notice that the first columns don't contain usefull data and that there are many variables with missing data. Besides,some of the variables, like stddev_, avg_, kurtosis_ etc. seem to be derived from the original data. We will exclude them in the next step. Please notice that although the amount of columns of both training and validation set is equal, the last column of the validation set is different (problem_id) in comparison to the last column of the training set (classe). Make sure that you apply the same transformations on both your training and validation set.</p>

<pre><code>summary(data)
summary(validation)
dim(data)
dim(validation)
</code></pre>

<p><strong>Remove unnecessary columns</strong></p>

<pre><code># first 7 columns don't contain useful info
data &lt;- data[,-seq(1:7)]
validation &lt;- validation[,-seq(1:7)]
</code></pre>

<p><strong>Remove columns with NAs</strong>
This reduces de amount of predictors to 53</p>

<pre><code># select columns that don't have NAs
indexNA &lt;- as.vector(sapply(data[,1:152],function(x) {length(which(is.na(x)))!=0}))
data &lt;- data[,!indexNA]
validation &lt;- validation[,!indexNA]
</code></pre>

<p><strong>Remove highly correlated variables</strong>
Highly correlated variables can sometimes reduce the performance of a model, and will be excluded. However, this way of selection is disputable: <a href="http://arxiv.org/abs/1310.5726">http://arxiv.org/abs/1310.5726</a></p>

<pre><code># set last (classe) and prior (- classe) column index
last &lt;- as.numeric(ncol(data))
prior &lt;- last - 1

# set variables to numerics for correlation check, except the "classe"
for (i in 1:prior) {
data[,i] &lt;- as.numeric(data[,i])
validation[,i] &lt;- as.numeric(validation[,i])
}

# check the correlations
cor.check &lt;- cor(data[, -c(last)])
diag(cor.check) &lt;- 0 
plot( levelplot(cor.check, 
                main ="Correlation matrix for all WLE features in training set",
                scales=list(x=list(rot=90), cex=1.0),))
</code></pre>

<p><img src="https://github.com/mdragt/machinelearning/blob/master/Images/CorMatrix.jpeg?raw=true" alt="Correlation Matrix"></p>

<pre><code># find the highly correlated variables
highly.cor &lt;- findCorrelation(cor(data[, -c(last)]), cutoff=0.9)

# remove highly correlated variables
data &lt;- data[, -highly.cor]
validation &lt;- validation[, -highly.cor]
</code></pre>

<p><strong>Preproccesing of the variables</strong>
The amount of predictors is now 46. We will continue with the preproccing of these predictors, by centering and scaling them. Remember that the last column of the validation set contained the problem_id.</p>

<pre><code># pre process variables
preObj &lt;-preProcess(data[,1:prior],method=c('knnImpute', 'center', 'scale'))
dataPrep &lt;- predict(preObj, data[,1:prior])
dataPrep$classe &lt;- data$classe

valPrep &lt;-predict(preObj,validation[,1:prior])
valPrep$problem_id &lt;- validation$problem_id
</code></pre>

<p><strong>Remove the near zero variables</strong>
Near zero variables have less prediction value, so we remove them. Although in this case, there are none to be elimnated.</p>

<pre><code># test near zero variance
myDataNZV &lt;- nearZeroVar(dataPrep, saveMetrics=TRUE)
if (any(myDataNZV$nzv)) nzv else message("No variables with near zero variance")
dataPrep &lt;- dataPrep[,myDataNZV$nzv==FALSE]
valPrep &lt;- valPrep[,myDataNZV$nzv==FALSE]
</code></pre>

<h3>
<a id="create-a-cross-validation-set" class="anchor" href="#create-a-cross-validation-set" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create a cross validation set</h3>

<p>To train and test the model, we create a training and a testing set.</p>

<pre><code># split dataset into training and test set
inTrain &lt;- createDataPartition(y=dataPrep$classe, p=0.7, list=FALSE )
training &lt;- dataPrep[inTrain,]
testing &lt;- dataPrep[-inTrain,]
</code></pre>

<h3>
<a id="train-model-1-random-forest" class="anchor" href="#train-model-1-random-forest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train Model 1: Random Forest</h3>

<p>Regarding the data, we will expect Decision Tree and Random Forest to give the best results. We start with Random Forest. First we set a seed to make this project reproducable. We will use the tuneRF function to calculate the optimal mtry and use that in the random forest function.</p>

<pre><code># set seed for reproducibility
set.seed(12345)

# get the best mtry
bestmtry &lt;- tuneRF(training[-last],training$classe, ntreeTry=100, 
                   stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE, dobest=FALSE)

mtry &lt;- bestmtry[as.numeric(which.min(bestmtry[,"OOBError"])),"mtry"]

# Model 1: RandomForest
wle.rf &lt;-randomForest(classe~.,data=training, mtry=mtry, ntree=501, 
                      keep.forest=TRUE, proximity=TRUE, 
                      importance=TRUE,test=testing)
</code></pre>

<h3>
<a id="results-of-model-1" class="anchor" href="#results-of-model-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results of Model 1</h3>

<p>First we plot the Out-Of-Bag (OOB) error-rate. Besides, we will investigate the mean decrease of both accuracy and Gini score. As we can see it was correct to use 501 trees. </p>

<pre><code># plot the Out of bag error estimates
layout(matrix(c(1,2),nrow=1), width=c(4,1)) 
par(mar=c(5,4,4,0)) #No margin on the right side
plot(wle.rf, log="y", main ="Out-of-bag (OOB) error estimate per Number of Trees")
par(mar=c(5,0,4,2)) #No margin on the left side
plot(c(0,1),type="n", axes=F, xlab="", ylab="")
legend("top", colnames(wle.rf$err.rate),col=1:6,cex=0.8,fill=1:6)
</code></pre>

<p><img src="/images/OOB.jpeg" alt="Out of bag error rate"></p>

<pre><code># plot the accuracy and Gini
varImpPlot(wle.rf, main="Mean Decrease of Accuracy and Gini per variable")
</code></pre>

<p><img src="/images/AccuracyGini.jpeg" alt="Accuracy and Gini scores"></p>

<pre><code># MDSplot (we couldn't execute this due to lack of memory)
MDSplot(wle.rf, training$classe)
</code></pre>

<h3>
<a id="accuracy-model-1-on-training-set-and-cross-validation-set" class="anchor" href="#accuracy-model-1-on-training-set-and-cross-validation-set" aria-hidden="true"><span class="octicon octicon-link"></span></a>Accuracy Model 1 on training set and cross validation set</h3>

<p>Here we use Model 1 to predict both the training as the testing set. With the test set, we obtain an accuracy of 0.9951, which seems to be acceptable. However, we will also test the Decision Tree model.</p>

<pre><code># results with training set
predict1 &lt;- predict(wle.rf, newdata=training)
confusionMatrix(predict1,training$classe)

Confusion Matrix and Statistics

#              Reference
# Prediction    A    B    C    D    E
#          A 3906    0    0    0    0
#          B    0 2658    0    0    0
#          C    0    0 2396    0    0
#          D    0    0    0 2252    0
#          E    0    0    0    0 2525

# Overall Statistics

#            Accuracy : 1          
#              95% CI : (0.9997, 1)
# No Information Rate : 0.2843     
# P-Value [Acc &gt; NIR] : &lt; 2.2e-16  

#               Kappa : 1          
# Mcnemar's Test P-Value : NA         

# Statistics by Class:

#                      Class: A Class: B Class: C Class: D Class: E
# Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
# Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
# Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
# Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
# Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
# Detection Rate         0.2843   0.1935   0.1744   0.1639   0.1838
# Detection Prevalence   0.2843   0.1935   0.1744   0.1639   0.1838
# Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000

# results with test set
predict2 &lt;- predict(wle.rf, newdata=testing)
confusionMatrix(predict2,testing$classe)

# Confusion Matrix and Statistics

#               Reference
# Prediction    A    B    C    D    E
#         A 1671    2    0    0    0
#         B    2 1134   11    0    0
#         C    0    3 1015    9    0
#         D    0    0    0  954    0
#         E    1    0    0    1 1082

# Overall Statistics

#             Accuracy : 0.9951          
#               95% CI : (0.9929, 0.9967)
#  No Information Rate : 0.2845          
#  P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

#                Kappa : 0.9938          
#  Mcnemar's Test P-Value : NA              

# Statistics by Class:

#                      Class: A Class: B Class: C Class: D Class: E
# Sensitivity            0.9982   0.9956   0.9893   0.9896   1.0000
# Specificity            0.9995   0.9973   0.9975   1.0000   0.9996
# Pos Pred Value         0.9988   0.9887   0.9883   1.0000   0.9982
# Neg Pred Value         0.9993   0.9989   0.9977   0.9980   1.0000
# Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
# Detection Rate         0.2839   0.1927   0.1725   0.1621   0.1839
# Detection Prevalence   0.2843   0.1949   0.1745   0.1621   0.1842
# Balanced Accuracy      0.9989   0.9964   0.9934   0.9948   0.9998
</code></pre>

<h3>
<a id="train-model-2-decision-tree" class="anchor" href="#train-model-2-decision-tree" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train Model 2: Decision Tree</h3>

<pre><code># Model 2: Decision Tree
dt &lt;- rpart(classe ~ ., data=training, method="class")

# fancyRpartPlot works for small trees, but not for ours
fancyRpartPlot(dt)
</code></pre>

<p><img src="/images/fancyPlot.jpeg" alt="Decision Tree Plot"></p>

<h3>
<a id="accuracy-model-2-on-training-set-and-cross-validation-set" class="anchor" href="#accuracy-model-2-on-training-set-and-cross-validation-set" aria-hidden="true"><span class="octicon octicon-link"></span></a>Accuracy Model 2 on training set and cross validation set</h3>

<p>As we can see, this model is not improving the performance, having an accuracy of 0.6989. Therefor, we will continue with model 1.</p>

<pre><code># cross validation
predictDT &lt;- predict(dt, testing, type = "class")
confusionMatrix(predictDT, testing$classe)

# Confusion Matrix and Statistics

#               Reference
#  Prediction    A    B    C    D    E
#           A 1506  190   51   67   49
#           B   53  616   59   92  184
#           C   44  199  867  180  242
#           D   67  114   46  616   99
#           E    4   20    3    9  508

# Overall Statistics

#             Accuracy : 0.6989         
#               95% CI : (0.687, 0.7106)
#  No Information Rate : 0.2845         
#  P-Value [Acc &gt; NIR] : &lt; 2.2e-16      

#                Kappa : 0.618          
# Mcnemar's Test P-Value : &lt; 2.2e-16      

# Statistics by Class:

#                      Class: A Class: B Class: C Class: D Class: E
# Sensitivity            0.8996   0.5408   0.8450   0.6390  0.46950
# Specificity            0.9152   0.9182   0.8631   0.9338  0.99250
# Pos Pred Value         0.8084   0.6135   0.5659   0.6539  0.93382
# Neg Pred Value         0.9582   0.8928   0.9635   0.9296  0.89253
# Prevalence             0.2845   0.1935   0.1743   0.1638  0.18386
# Detection Rate         0.2559   0.1047   0.1473   0.1047  0.08632
# Detection Prevalence   0.3166   0.1706   0.2603   0.1601  0.09244
# Balanced Accuracy      0.9074   0.7295   0.8541   0.7864  0.73100
</code></pre>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h3>

<p>Finally, as the Random Forest model gave us the best result, we will apply that to our validation set and create the documents to submit.</p>

<pre><code># Predict the class of the validation set
answer&lt;-predict(wle.rf,valPrep)
answer

# code as suggested by Coursera
pml_write_files = function(x){
    n = length(x)
    for(i in 1:n){
        filename = paste0("problem_id_",i,".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
}

pml_write_files(answer)
</code></pre>

<h2>
<a id="data" class="anchor" href="#data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data</h2>

<p>The training data for this project are available here: <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a></p>

<p>The test data are available here: <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a></p>

<p>The data for this project come from this source: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>. </p>

<p>Read more: <a href="http://groupware.les.inf.puc-rio.br/har#ixzz3TROgwbfY">http://groupware.les.inf.puc-rio.br/har#ixzz3TROgwbfY</a></p>

<p>Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. </p>

<h2>
<a id="notes" class="anchor" href="#notes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Notes</h2>

<p>This project is an assignment for the Coursera Practical Machine Learning course</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Machinelearning maintained by <a href="https://github.com/mdragt">mdragt</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
